# Can NLP predict the popularity of your favorite anime before huge investments? A study with LLM's

<center>
    <p><img align="center" href="https://arxiv.org" src="https://img.shields.io/badge/arXiv-mimi.mimim-b31b1b.svg"></p>
    <p> </p>
</center>

[![arXiv](https://img.shields.io/badge/arXiv-mimi.mimim-b31b1b.svg)](https://arxiv.org)
[![SX1.1](https://img.shields.io/badge/StoneAxe-V1.1-orange)](https://google.com)
[![licence](https://img.shields.io/badge/Licence-Apache_2.0-gray)]([https://google.com](https://www.apache.org/licenses/LICENSE-2.0))


![banner](https://github.com/JesusASmx/Correlation-between-anime-synopsis-and-popularity-with-LLM-s/blob/main/assets/anime_pop2.jpg)

 (requires ollama) <br/><br/> Database: for reviewers, it was uploaded in the journal's webpage

Links for results reproduction:

GPT2 synopsis embeddings
Mistral and Llama2 synopsis embeddings
<i>(requires ollama)</i>
StoneAxe 1.0 embeddings
<i>(requires ollama)</i>
PCA representations
Regressions



DISCLAIMER: Tensors cannot be uploaded here due GitHub's storage policy. However, the provided code should reproduce them. You can request the originals to jesus.jorge.armenta@gmail.com

SPECIFICATIONS FOR REPRODUCIBILITY:

Library versions:
Transformers - Latest (march 2024)
SpaCy - Latest (march 2024)
Torch - 1.10.1
We first installed the latest Transformers library, and then Torch==1.10.1.

Employed hardware:
CUDA ?????? 46gb VRAM.
OS: Ubuntu.


